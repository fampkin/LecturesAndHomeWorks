{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `recipes_sample.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>description</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>44123</td>\n",
       "      <td>90</td>\n",
       "      <td>35193</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>67664</td>\n",
       "      <td>10</td>\n",
       "      <td>91970</td>\n",
       "      <td>2003-07-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>38798</td>\n",
       "      <td>30</td>\n",
       "      <td>1533</td>\n",
       "      <td>2002-08-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>these were so go, it surprised even me.</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>35173</td>\n",
       "      <td>45</td>\n",
       "      <td>22724</td>\n",
       "      <td>2002-07-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my sister-in-law made these for us at a family...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>84797</td>\n",
       "      <td>25</td>\n",
       "      <td>4470</td>\n",
       "      <td>2004-02-23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i think a fondue is a very romantic casual din...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name     id  minutes  contributor_id  \\\n",
       "0     george s at the cove  black bean soup  44123       90           35193   \n",
       "1        healthy for them  yogurt popsicles  67664       10           91970   \n",
       "2              i can t believe it s spinach  38798       30            1533   \n",
       "3                      italian  gut busters  35173       45           22724   \n",
       "4  love is in the air  beef fondue   sauces  84797       25            4470   \n",
       "\n",
       "    submitted  n_steps                                        description  \\\n",
       "0  2002-10-25      NaN  an original recipe created by chef scott meska...   \n",
       "1  2003-07-26      NaN  my children and their friends ask for my homem...   \n",
       "2  2002-08-29      NaN            these were so go, it surprised even me.   \n",
       "3  2002-07-27      NaN  my sister-in-law made these for us at a family...   \n",
       "4  2004-02-23      4.0  i think a fondue is a very romantic casual din...   \n",
       "\n",
       "   n_ingredients  \n",
       "0           18.0  \n",
       "1            NaN  \n",
       "2            8.0  \n",
       "3            NaN  \n",
       "4            NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "recipes = pd.read_csv('recipes_sample.csv')\n",
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/fampkin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/fampkin/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          an\n",
       "1    original\n",
       "2      recipe\n",
       "3     created\n",
       "4          by\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list()\n",
    "\n",
    "for description in recipes['description']:\n",
    "    if isinstance(description, str):\n",
    "        tokens = nltk.word_tokenize(description)\n",
    "        words.extend(tokens)\n",
    "\n",
    "ds = pd.Series(words)\n",
    "ds.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Пара 1:\n",
      "Слово 1: ''m'\n",
      "Слово 2: 'bulk'\n",
      "Расстояние редактирования: 4\n",
      "\n",
      "Пара 2:\n",
      "Слово 1: 'and'\n",
      "Слово 2: 'href='\n",
      "Расстояние редактирования: 5\n",
      "\n",
      "Пара 3:\n",
      "Слово 1: 'isle'\n",
      "Слово 2: 'title'\n",
      "Расстояние редактирования: 2\n",
      "\n",
      "Пара 4:\n",
      "Слово 1: 'turning'\n",
      "Слово 2: 'i'\n",
      "Расстояние редактирования: 6\n",
      "\n",
      "Пара 5:\n",
      "Слово 1: 'fresh'\n",
      "Слово 2: 'cookbook'\n",
      "Расстояние редактирования: 8\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import edit_distance\n",
    "\n",
    "random_words = ds.sample(10).values\n",
    "\n",
    "for i in range(0, 10, 2):\n",
    "    word1 = random_words[i]\n",
    "    word2 = random_words[i+1]\n",
    "    distance = edit_distance(word1, word2)\n",
    "    print(f\"\\nПара {i//2 + 1}:\")\n",
    "    print(f\"Слово 1: '{word1}'\")\n",
    "    print(f\"Слово 2: '{word2}'\")\n",
    "    print(f\"Расстояние редактирования: {distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ближайшие слова к 'cooking': ['cooking', 'looking', 'cookin', 'cooling', 'ccoking', \"'cooking\", 'cookings', 'cooking_', 'choking', 'cookiing']\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "word = 'cooking'\n",
    "\n",
    "def get_k_nearest_words(word, words, k):\n",
    "    words_dist = dict()\n",
    "    for w in words:\n",
    "        distance = edit_distance(word, w)\n",
    "        words_dist[w] = distance\n",
    "    words_dist = sorted(words_dist.items(), key=lambda x: x[1])\n",
    "    return [d[0] for d in words_dist[:k]]\n",
    "\n",
    "nearest_words = get_k_nearest_words(word, words, k)\n",
    "print(f\"Ближайшие слова к '{word}': {nearest_words}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/fampkin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>an</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>origin</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recipe</th>\n",
       "      <td>recip</td>\n",
       "      <td>recipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <td>creat</td>\n",
       "      <td>created</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         stemmed_word normalized_word\n",
       "word                                 \n",
       "an                 an              an\n",
       "original       origin        original\n",
       "recipe          recip          recipe\n",
       "created         creat         created\n",
       "by                 by              by"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'word': words})\n",
    "df['stemmed_word'] = df['word'].apply(lambda x: stemmer.stem(x))\n",
    "df['normalized_word'] = df['word'].apply(lambda x: lemmatizer.lemmatize(x))\n",
    "\n",
    "df.set_index('word', inplace=True)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fampkin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Статистика:\n",
      "Всего слов: 1242181\n",
      "Слов после удаления стоп-слов: 742017\n",
      "Доля стоп-слов: 40.26%\n",
      "\n",
      "Примеры слов после фильтрации:\n",
      "1    original\n",
      "2      recipe\n",
      "3     created\n",
      "5        chef\n",
      "6       scott\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "filtered_words = ds[~ds.isin(stop_words)]\n",
    "filtered_words.head()\n",
    "\n",
    "print(\"\\nСтатистика:\")\n",
    "print(f\"Всего слов: {len(ds)}\")\n",
    "print(f\"Слов после удаления стоп-слов: {len(filtered_words)}\")\n",
    "print(f\"Доля стоп-слов: {((len(ds) - len(filtered_words)) / len(ds)) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nПримеры слов после фильтрации:\")\n",
    "print(filtered_words.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adopt</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>another</th>\n",
       "      <th>are</th>\n",
       "      <th>at</th>\n",
       "      <th>banana</th>\n",
       "      <th>bits</th>\n",
       "      <th>bloomingdale</th>\n",
       "      <th>bread</th>\n",
       "      <th>...</th>\n",
       "      <th>up</th>\n",
       "      <th>use</th>\n",
       "      <th>very</th>\n",
       "      <th>want</th>\n",
       "      <th>was</th>\n",
       "      <th>way</th>\n",
       "      <th>we</th>\n",
       "      <th>while</th>\n",
       "      <th>winter</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spicy szechuan noodles  dan dan mian</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet and salty cereal bars</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113606</td>\n",
       "      <td>0.169634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169634</td>\n",
       "      <td>0.169634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granny s tater soup</th>\n",
       "      <td>0.153034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123467</td>\n",
       "      <td>0.153034</td>\n",
       "      <td>0.153034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153034</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low fat morning glory muffins</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aunt muriel s banana bread</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249227</td>\n",
       "      <td>0.166910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         adopt        an       and   another  \\\n",
       "name                                                                           \n",
       "spicy szechuan noodles  dan dan mian  0.000000  0.000000  0.000000  0.000000   \n",
       "sweet and salty cereal bars           0.000000  0.000000  0.113606  0.169634   \n",
       "granny s tater soup                   0.153034  0.000000  0.000000  0.000000   \n",
       "low fat morning glory muffins         0.000000  0.000000  0.371921  0.000000   \n",
       "aunt muriel s banana bread            0.000000  0.249227  0.166910  0.000000   \n",
       "\n",
       "                                           are        at    banana      bits  \\\n",
       "name                                                                           \n",
       "spicy szechuan noodles  dan dan mian  0.000000  0.000000  0.000000  0.000000   \n",
       "sweet and salty cereal bars           0.000000  0.000000  0.000000  0.000000   \n",
       "granny s tater soup                   0.000000  0.153034  0.000000  0.000000   \n",
       "low fat morning glory muffins         0.138836  0.000000  0.000000  0.138836   \n",
       "aunt muriel s banana bread            0.000000  0.000000  0.249227  0.000000   \n",
       "\n",
       "                                      bloomingdale     bread  ...        up  \\\n",
       "name                                                          ...             \n",
       "spicy szechuan noodles  dan dan mian      0.000000  0.000000  ...  0.000000   \n",
       "sweet and salty cereal bars               0.000000  0.000000  ...  0.169634   \n",
       "granny s tater soup                       0.153034  0.000000  ...  0.000000   \n",
       "low fat morning glory muffins             0.000000  0.000000  ...  0.000000   \n",
       "aunt muriel s banana bread                0.000000  0.249227  ...  0.000000   \n",
       "\n",
       "                                           use      very      want       was  \\\n",
       "name                                                                           \n",
       "spicy szechuan noodles  dan dan mian  0.000000  0.000000  0.000000  0.000000   \n",
       "sweet and salty cereal bars           0.169634  0.000000  0.000000  0.000000   \n",
       "granny s tater soup                   0.000000  0.123467  0.153034  0.153034   \n",
       "low fat morning glory muffins         0.000000  0.000000  0.000000  0.000000   \n",
       "aunt muriel s banana bread            0.000000  0.201075  0.000000  0.000000   \n",
       "\n",
       "                                           way        we     while    winter  \\\n",
       "name                                                                           \n",
       "spicy szechuan noodles  dan dan mian  0.000000  0.000000  0.000000  0.000000   \n",
       "sweet and salty cereal bars           0.339267  0.000000  0.169634  0.000000   \n",
       "granny s tater soup                   0.000000  0.306068  0.000000  0.153034   \n",
       "low fat morning glory muffins         0.000000  0.000000  0.000000  0.000000   \n",
       "aunt muriel s banana bread            0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                          with  \n",
       "name                                            \n",
       "spicy szechuan noodles  dan dan mian  0.000000  \n",
       "sweet and salty cereal bars           0.000000  \n",
       "granny s tater soup                   0.000000  \n",
       "low fat morning glory muffins         0.555345  \n",
       "aunt muriel s banana bread            0.000000  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_recipes = recipes.sample(5)\n",
    "\n",
    "vectors = tfidf.fit_transform(random_recipes['description'].fillna(''))\n",
    "\n",
    "dense_vectors = vectors.todense()\n",
    "\n",
    "vector_df = pd.DataFrame(\n",
    "    dense_vectors,\n",
    "    index=random_recipes['name'],\n",
    "    columns=tfidf.get_feature_names_out()\n",
    ")\n",
    "\n",
    "vector_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>spicy szechuan noodles  dan dan mian</th>\n",
       "      <th>sweet and salty cereal bars</th>\n",
       "      <th>granny s tater soup</th>\n",
       "      <th>low fat morning glory muffins</th>\n",
       "      <th>aunt muriel s banana bread</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spicy szechuan noodles  dan dan mian</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet and salty cereal bars</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885836</td>\n",
       "      <td>0.875302</td>\n",
       "      <td>0.981038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granny s tater soup</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.980941</td>\n",
       "      <td>0.975174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low fat morning glory muffins</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875302</td>\n",
       "      <td>0.980941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aunt muriel s banana bread</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981038</td>\n",
       "      <td>0.975174</td>\n",
       "      <td>0.937923</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                                  spicy szechuan noodles  dan dan mian  \\\n",
       "name                                                                         \n",
       "spicy szechuan noodles  dan dan mian                                   0.0   \n",
       "sweet and salty cereal bars                                            1.0   \n",
       "granny s tater soup                                                    1.0   \n",
       "low fat morning glory muffins                                          1.0   \n",
       "aunt muriel s banana bread                                             1.0   \n",
       "\n",
       "name                                  sweet and salty cereal bars  \\\n",
       "name                                                                \n",
       "spicy szechuan noodles  dan dan mian                     1.000000   \n",
       "sweet and salty cereal bars                              0.000000   \n",
       "granny s tater soup                                      0.885836   \n",
       "low fat morning glory muffins                            0.875302   \n",
       "aunt muriel s banana bread                               0.981038   \n",
       "\n",
       "name                                  granny s tater soup  \\\n",
       "name                                                        \n",
       "spicy szechuan noodles  dan dan mian             1.000000   \n",
       "sweet and salty cereal bars                      0.885836   \n",
       "granny s tater soup                              0.000000   \n",
       "low fat morning glory muffins                    0.980941   \n",
       "aunt muriel s banana bread                       0.975174   \n",
       "\n",
       "name                                  low fat morning glory muffins  \\\n",
       "name                                                                  \n",
       "spicy szechuan noodles  dan dan mian                       1.000000   \n",
       "sweet and salty cereal bars                                0.875302   \n",
       "granny s tater soup                                        0.980941   \n",
       "low fat morning glory muffins                              0.000000   \n",
       "aunt muriel s banana bread                                 0.937923   \n",
       "\n",
       "name                                  aunt muriel s banana bread  \n",
       "name                                                              \n",
       "spicy szechuan noodles  dan dan mian                    1.000000  \n",
       "sweet and salty cereal bars                             0.981038  \n",
       "granny s tater soup                                     0.975174  \n",
       "low fat morning glory muffins                           0.937923  \n",
       "aunt muriel s banana bread                              0.000000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "n_recipes = len(random_recipes)\n",
    "distances = np.zeros((n_recipes, n_recipes))\n",
    "\n",
    "for i in range(n_recipes):\n",
    "    for j in range(n_recipes):\n",
    "        distances[i, j] = cosine(vector_df.iloc[i], vector_df.iloc[j])\n",
    "\n",
    "distance_df = pd.DataFrame(\n",
    "    distances,\n",
    "    index=random_recipes['name'],\n",
    "    columns=random_recipes['name']\n",
    ")\n",
    "\n",
    "distance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анализ схожести рецептов:\n",
      "\n",
      "Наиболее похожая пара рецептов:\n",
      "1. sweet and salty cereal bars\n",
      "2. low fat morning glory muffins\n",
      "Косинусное расстояние между ними: 0.875\n",
      "\n",
      "Описания этих рецептов:\n",
      "\n",
      "Рецепт 1: tasty way to satisfy those \"sweet and salty\" cravings. :) i found this recipe online while searching for a way to use up the rest of the crispix cereal i had purchased for another recipe.\n",
      "\n",
      "Рецепт 2: lovely muffins packed with succulent bits of raisins and carrot, studded with crunchy sunflower seeds, and permeated with the flavors of orange and cinnamon. served with fresh fruit and scrambled eggs, these are great for a special breakfast!\n",
      "\n",
      "Объяснение схожести:\n",
      "\n",
      "Общие важные слова в этих рецептах:\n",
      "with      0.308408\n",
      "and       0.151231\n",
      "recipe    0.115102\n",
      "way       0.115102\n",
      "for       0.087469\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "distances_no_diagonal = distance_df.copy()\n",
    "np.fill_diagonal(distances_no_diagonal.values, 1.0)\n",
    "\n",
    "min_distance = distances_no_diagonal.min().min()\n",
    "most_similar_pair = np.where(distances_no_diagonal == min_distance)\n",
    "recipe1 = distances_no_diagonal.index[most_similar_pair[0][0]]\n",
    "recipe2 = distances_no_diagonal.columns[most_similar_pair[1][0]]\n",
    "\n",
    "print(\"Анализ схожести рецептов:\")\n",
    "print(f\"\\nНаиболее похожая пара рецептов:\")\n",
    "print(f\"1. {recipe1}\")\n",
    "print(f\"2. {recipe2}\")\n",
    "print(f\"Косинусное расстояние между ними: {min_distance:.3f}\")\n",
    "\n",
    "print(\"\\nОписания этих рецептов:\")\n",
    "print(f\"\\nРецепт 1: {recipes[recipes['name'] == recipe1]['description'].values[0]}\")\n",
    "print(f\"\\nРецепт 2: {recipes[recipes['name'] == recipe2]['description'].values[0]}\")\n",
    "\n",
    "print(\"\\nОбъяснение схожести:\")\n",
    "common_words = vector_df.loc[[recipe1, recipe2]].multiply(vector_df.loc[[recipe1, recipe2]]).sum()\n",
    "top_common_words = common_words[common_words > 0].sort_values(ascending=False).head(5)\n",
    "print(\"\\nОбщие важные слова в этих рецептах:\")\n",
    "print(top_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Степень схожести:**\n",
    "   - Косинусное расстояние 0.875 указывает на относительно низкую схожесть рецептов (чем ближе к 1, тем менее похожи рецепты)\n",
    "   - Это объяснимо, так как рецепты описывают разные блюда: батончики из хлопьев и маффины\n",
    "\n",
    "2. **Анализ общих слов:**\n",
    "   - Наиболее значимые общие слова (\"with\", \"and\", \"recipe\", \"way\", \"for\") являются скорее структурными, чем содержательными\n",
    "   - Это указывает на схожесть в стиле описания, но не в самих рецептах\n",
    "\n",
    "3. **Различия в рецептах:**\n",
    "   - Первый рецепт о сладко-соленых батончиках из хлопьев\n",
    "   - Второй рецепт о низкокалорийных маффинах с изюмом, морковью и семечками\n",
    "   - Ингредиенты и способы приготовления существенно различаются\n",
    "\n",
    "4. **Почему все же есть некоторая схожесть:**\n",
    "   - Оба рецепта относятся к категории выпечки/снеков\n",
    "   - В обоих описаниях используется позитивная лексика (\"tasty\", \"lovely\")\n",
    "   - Оба рецепта включают описание текстур и вкусовых качеств\n",
    "   - Оба являются закусками/десертами\n",
    "\n",
    "Таким образом, несмотря на то что рецепты описывают разные блюда, они имеют схожую структуру описания и относятся к похожей категории продуктов, что объясняет наличие общих слов в их векторных представлениях.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
